{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import gc\n",
    "\n",
    "def extractDateFeatures(df, sourceName):\n",
    "    seasons = [0,0,1,1,1,2,2,2,3,3,3,0] #dec - feb is winter, then spring, summer, fall etc\n",
    "    \n",
    "    #df['df_year_' + sourceName] = pd.to_datetime(df[sourceName]).dt.year.astype('uint16')\n",
    "    #df['df_quarter_' + sourceName] = df[sourceName].apply(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ).month-1)//3 + 1)\n",
    "    #df['df_yearmonth_' + sourceName] = df[sourceName].apply(lambda x: int(str(datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ).year) \\\n",
    "    #                                                        + str(datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ).month)) )\n",
    "    #df['df_month_' + sourceName] = pd.to_datetime(df[sourceName]).dt.month.astype('uint8')\n",
    "    df['df_day_' + sourceName] = pd.to_datetime(df[sourceName]).dt.day.astype('uint8')\n",
    "    df['df_weekday_' + sourceName] = pd.to_datetime(df[sourceName]).dt.dayofweek.astype('uint8')\n",
    "    df['df_hour_' + sourceName] = pd.to_datetime(df[sourceName]).dt.hour.astype('uint8')\n",
    "    #df['df_season_' + sourceName] = df[sourceName].apply(lambda x: seasons[(datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\" ).month-1)])\n",
    "    \n",
    "    #df['df_season_' + sourceName]      = df['df_season_' + sourceName].astype('uint8')\n",
    "    #df['df_quarter_' + sourceName]      = df['df_quarter_' + sourceName].astype('uint8') \n",
    "    #df['df_yearmonth_' + sourceName]      = df['df_yearmonth_' + sourceName].astype('uint32') \n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }    \n",
    "\n",
    "train=pd.read_csv(\"/Users/schwalmdaniel/hullaballoo_android/ml/talkingdata-adtracking-fraud-detection/train_sample.csv\",\\\n",
    "                 dtype=dtypes)\n",
    "extractDateFeatures(train,'click_time')\n",
    "\n",
    "GROUPBY_AGGREGATIONS = [\n",
    "    # Variance in day, for ip-app-channel\n",
    "    {'groupby': ['ip','app','channel'], 'select': 'df_day_click_time', 'agg': 'var', 'type': 'float32'},\n",
    "    # Variance in day, for ip-app-device\n",
    "    {'groupby': ['ip','app','device'], 'select': 'df_day_click_time', 'agg': 'var', 'type': 'float32'},\n",
    "    # Variance in day, for ip-app-os\n",
    "    {'groupby': ['ip','app','os'], 'select': 'df_day_click_time', 'agg': 'var', 'type': 'float32'},\n",
    "    \n",
    "    # Variance in hour, for ip-app-channel\n",
    "    #{'groupby': ['ip','app','channel'], 'select': 'hour', 'agg': 'var'},\n",
    "    # Variance in hour, for ip-app-device\n",
    "    #{'groupby': ['ip','app','device'], 'select': 'hour', 'agg': 'var'},\n",
    "    # Variance in hour, for ip-app-os\n",
    "    #{'groupby': ['ip','app','os'], 'select': 'hour', 'agg': 'var'},\n",
    "\n",
    "    # Count, for ip-day\n",
    "    #{'groupby': ['ip','day'], 'select': 'channel', 'agg': 'count'},\n",
    "    # Count, for ip-day\n",
    "    #{'groupby': ['ip','day'], 'select': 'device', 'agg': 'count'},\n",
    "    # Count, for ip-day\n",
    "    #{'groupby': ['ip','day'], 'select': 'os', 'agg': 'count'},\n",
    "    \n",
    "    # Count, for ip-hour\n",
    "   # {'groupby': ['ip','hour'], 'select': 'channel', 'agg': 'count'},\n",
    "    # Count, for ip-hour\n",
    "    #{'groupby': ['ip','hour'], 'select': 'device', 'agg': 'count'},\n",
    "    # Count, for ip-hour\n",
    "    #{'groupby': ['ip','hour'], 'select': 'os', 'agg': 'count'},\n",
    "\n",
    "    # Count, for ip-day-hour\n",
    "    {'groupby': ['ip','df_day_click_time','df_hour_click_time'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},\n",
    "    # Count, for ip-day-hour\n",
    "    #{'groupby': ['ip','day','hour'], 'select': 'device', 'agg': 'count', 'type': 'uint32'},\n",
    "    # Count, for ip-day-hour\n",
    "   # {'groupby': ['ip','day','hour'], 'select': 'os', 'agg': 'count', 'type': 'uint32'},\n",
    "    \n",
    "    # Count, for ip-app\n",
    "    {'groupby': ['ip', 'app'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},        \n",
    "    # Count, for ip-app-os\n",
    "    {'groupby': ['ip', 'app', 'os'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},\n",
    "    # Count, for ip-app-day-hour\n",
    "    {'groupby': ['ip','app','df_day_click_time','df_hour_click_time'], 'select': 'channel', 'agg': 'count', 'type': 'uint32'},\n",
    "    \n",
    "    # Mean hour, for ip-app-channel\n",
    "    {'groupby': ['ip','app','channel'], 'select': 'df_hour_click_time', 'agg': 'mean', 'type': 'float32', 'type': 'float32'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"/Users/schwalmdaniel/hullaballoo_android/ml/talkingdata-adtracking-fraud-detection/test 3.csv\"\\\n",
    "                 ,nrows=100000, dtype=dtypes)\n",
    "extractDateFeatures(test,'click_time')\n",
    "\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec in GROUPBY_AGGREGATIONS:\n",
    "    #print(f\"Grouping by {spec['groupby']}, and aggregating {spec['select']} with {spec['agg']}\")\n",
    "    \n",
    "    # Unique list of features to select\n",
    "    all_features = list(set(spec['groupby'] + [spec['select']]))\n",
    "    # Name of new feature\n",
    "    new_feature = '{}_{}_{}'.format('_'.join(spec['groupby']), spec['agg'], spec['select'])\n",
    "     # Perform the groupby\n",
    "    gp = train[all_features]. \\\n",
    "        groupby(spec['groupby'])[spec['select']]. \\\n",
    "        agg(spec['agg']). \\\n",
    "        reset_index(). \\\n",
    "        rename(index=str, columns={spec['select']: new_feature}).astype(spec['type'])\n",
    "     # Merge back to X_train\n",
    "    train = train.merge(gp, on=spec['groupby'], how='left')\n",
    "    \n",
    "    gp = test[all_features]. \\\n",
    "        groupby(spec['groupby'])[spec['select']]. \\\n",
    "        agg(spec['agg']). \\\n",
    "        reset_index(). \\\n",
    "        rename(index=str, columns={spec['select']: new_feature}).astype(spec['type'])\n",
    "     # Merge back to X_train\n",
    "    test = test.merge(gp, on=spec['groupby'], how='left')\n",
    "    \n",
    "del gp\n",
    "gc.collect()\n",
    "\n",
    "train.fillna(0,inplace=True)\n",
    "test.fillna(0,inplace=True)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.919153\n",
      "[200]\tvalid_0's auc: 0.955972\n",
      "[300]\tvalid_0's auc: 0.970849\n",
      "[400]\tvalid_0's auc: 0.976085\n",
      "[500]\tvalid_0's auc: 0.977016\n",
      "Early stopping, best iteration is:\n",
      "[470]\tvalid_0's auc: 0.977486\n",
      "Important features:\n",
      "[('ip', 2761), ('app', 2135), ('channel', 1835), ('os', 1622), ('ip_app_channel_mean_df_hour_click_time', 805), ('df_hour_click_time', 792), ('device', 635), ('df_day_click_time', 371), ('ip_df_day_click_time_df_hour_click_time_count_channel', 106), ('ip_app_count_channel', 98), ('ip_app_device_var_df_day_click_time', 70), ('df_weekday_click_time', 48), ('ip_app_os_count_channel', 5)]\n",
      "0 AUC: 0.9774860791693908\n",
      "AUC = 0.977486 +/- 0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = train['is_attributed']\n",
    "x_train = train.drop(['is_attributed','click_time','attributed_time'],axis=1)\n",
    "#train2 = train.drop(['is_attributed','click_time','attributed_time'],axis=1)\n",
    "y_test = train['is_attributed']\n",
    "x_test = test.drop(['click_time'],axis=1)\n",
    "\n",
    "#x_train, test2, y_train, y_test = train_test_split(train2, y, test_size=0.33, random_state=42)\n",
    "\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 2\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "auc_buf = []   \n",
    "\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 12,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_threads': 4,\n",
    "        'lambda_l2': 1.5,\n",
    "        'min_gain_to_split': 0,\n",
    "    }  \n",
    "\n",
    "for train_index, valid_index in kf.split(x_train):\n",
    "    print('Fold {}/{}'.format(cnt + 1, n_splits))\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb.Dataset(x_train.loc[train_index], y_train.loc[train_index], feature_name=x_train.columns.tolist()),\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb.Dataset(x_train.loc[valid_index], y_train.loc[valid_index])],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        print(tuples[:200])\n",
    "\n",
    "    p = model.predict(x_train.loc[valid_index], num_iteration=model.best_iteration)\n",
    "    auc = roc_auc_score(y_train.loc[valid_index], p)\n",
    "\n",
    "    print('{} AUC: {}'.format(cnt, auc))\n",
    "\n",
    "    p = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p)\n",
    "    else:\n",
    "        p_buf += np.array(p)\n",
    "    auc_buf.append(auc)\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt > 0: # Comment this to run several folds\n",
    "        break\n",
    "    \n",
    "    '''del model\n",
    "    gc.collect'''\n",
    "\n",
    "auc_mean = np.mean(auc_buf)\n",
    "auc_std = np.std(auc_buf)\n",
    "print('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))\n",
    "\n",
    "preds = p_buf/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0       0.002558\n",
       "1         1       0.004158\n",
       "2         2       0.002363\n",
       "3         3       0.002354\n",
       "4         4       0.002671"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['click_id'] = test['click_id']\n",
    "subm['is_attributed'] = preds\n",
    "subm.to_csv('talkingdata1.csv', index=False,quoting=csv.QUOTE_NONNUMERIC)\n",
    "subm.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
