{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "root = '/Users/schwalmdaniel/github/kaggle/mnist'\n",
    "#root = 'd:/dev/python/kaggle/titanic'\n",
    "\n",
    "train=pd.read_csv(root + \"/train.csv\")\n",
    "test=pd.read_csv(root + \"/test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning from 42000 rows\n"
     ]
    }
   ],
   "source": [
    "X = train.drop(['label'], axis=1)\n",
    "# create our feature matrix by removing the response variable\n",
    "print (\"learning from {} rows\".format(X.shape[0]))\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data. Each pixel comes with a value between 0-255. CNN works better with values between 0-1.\n",
    "X /= 255.0\n",
    "test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X = X.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "y = to_categorical(y, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 229s - loss: 0.4194 - acc: 0.8646 - val_loss: 0.0620 - val_acc: 0.9817\n",
      "Epoch 2/30\n",
      " - 233s - loss: 0.1276 - acc: 0.9616 - val_loss: 0.0428 - val_acc: 0.9886\n",
      "Epoch 3/30\n",
      " - 282s - loss: 0.0901 - acc: 0.9726 - val_loss: 0.0437 - val_acc: 0.9864\n",
      "Epoch 4/30\n",
      " - 287s - loss: 0.0808 - acc: 0.9762 - val_loss: 0.0580 - val_acc: 0.9824\n",
      "Epoch 5/30\n",
      " - 279s - loss: 0.0717 - acc: 0.9786 - val_loss: 0.0410 - val_acc: 0.9881\n",
      "Epoch 6/30\n",
      " - 231s - loss: 0.0656 - acc: 0.9808 - val_loss: 0.0411 - val_acc: 0.9888\n",
      "Epoch 7/30\n",
      " - 240s - loss: 0.0611 - acc: 0.9819 - val_loss: 0.0386 - val_acc: 0.9919\n",
      "Epoch 8/30\n",
      " - 235s - loss: 0.0584 - acc: 0.9824 - val_loss: 0.0364 - val_acc: 0.9919\n",
      "Epoch 9/30\n",
      " - 235s - loss: 0.0600 - acc: 0.9828 - val_loss: 0.0294 - val_acc: 0.9910\n",
      "Epoch 10/30\n",
      " - 236s - loss: 0.0589 - acc: 0.9830 - val_loss: 0.0340 - val_acc: 0.9912\n",
      "Epoch 11/30\n",
      " - 236s - loss: 0.0562 - acc: 0.9836 - val_loss: 0.0335 - val_acc: 0.9907\n",
      "Epoch 12/30\n",
      " - 236s - loss: 0.0560 - acc: 0.9841 - val_loss: 0.0379 - val_acc: 0.9912\n",
      "Epoch 13/30\n",
      " - 237s - loss: 0.0582 - acc: 0.9838 - val_loss: 0.0315 - val_acc: 0.9912\n",
      "Epoch 14/30\n",
      " - 238s - loss: 0.0561 - acc: 0.9845 - val_loss: 0.0337 - val_acc: 0.9910\n",
      "Epoch 15/30\n",
      " - 236s - loss: 0.0576 - acc: 0.9839 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "Epoch 16/30\n",
      " - 237s - loss: 0.0597 - acc: 0.9842 - val_loss: 0.0330 - val_acc: 0.9910\n",
      "Epoch 17/30\n",
      " - 235s - loss: 0.0599 - acc: 0.9839 - val_loss: 0.0372 - val_acc: 0.9898\n",
      "Epoch 18/30\n",
      " - 235s - loss: 0.0621 - acc: 0.9840 - val_loss: 0.0303 - val_acc: 0.9917\n",
      "Epoch 19/30\n",
      " - 236s - loss: 0.0643 - acc: 0.9839 - val_loss: 0.0341 - val_acc: 0.9917\n",
      "Epoch 20/30\n",
      " - 699s - loss: 0.0604 - acc: 0.9846 - val_loss: 0.0325 - val_acc: 0.9919\n",
      "Epoch 21/30\n",
      " - 241s - loss: 0.0652 - acc: 0.9832 - val_loss: 0.0440 - val_acc: 0.9907\n",
      "Epoch 22/30\n",
      " - 234s - loss: 0.0666 - acc: 0.9827 - val_loss: 0.0424 - val_acc: 0.9898\n",
      "Epoch 23/30\n",
      " - 233s - loss: 0.0661 - acc: 0.9838 - val_loss: 0.0462 - val_acc: 0.9907\n",
      "Epoch 24/30\n",
      " - 234s - loss: 0.0715 - acc: 0.9828 - val_loss: 0.0386 - val_acc: 0.9907\n",
      "Epoch 25/30\n",
      " - 237s - loss: 0.0705 - acc: 0.9824 - val_loss: 0.0445 - val_acc: 0.9893\n",
      "Epoch 26/30\n",
      " - 236s - loss: 0.0730 - acc: 0.9823 - val_loss: 0.0389 - val_acc: 0.9902\n",
      "Epoch 27/30\n",
      " - 2034s - loss: 0.0683 - acc: 0.9833 - val_loss: 0.0374 - val_acc: 0.9905\n",
      "Epoch 28/30\n",
      " - 1647s - loss: 0.0752 - acc: 0.9824 - val_loss: 0.0334 - val_acc: 0.9912\n",
      "Epoch 29/30\n",
      " - 234s - loss: 0.0752 - acc: 0.9820 - val_loss: 0.0286 - val_acc: 0.9924\n",
      "Epoch 30/30\n",
      " - 231s - loss: 0.0766 - acc: 0.9821 - val_loss: 0.0390 - val_acc: 0.9905\n"
     ]
    }
   ],
   "source": [
    "#model = Sequential()\n",
    "\n",
    "#model.add(Conv2D(filters = 32, kernel_size = (5,5),activation ='relu',input_shape = (28,28,1)))\n",
    "#model.add(Conv2D(filters = 32, kernel_size = (5,5),activation ='relu'))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "#model.compile(Adam(lr=.0001), loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#history = model.fit(X, y, batch_size = 100, epochs = 10, validation_split=0.1,verbose = 2)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "epochs = 30\n",
    "batch_size=90\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),epochs = epochs, validation_data=(X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(test,batch_size=batch_size,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(root + \"/test.csv\")\n",
    "\n",
    "predicted = pd.DataFrame()\n",
    "predicted['ImageId'] = test.index + 1\n",
    "predicted['Label'] = preds\n",
    "predicted[['ImageId', 'Label']] = predicted[['ImageId', 'Label']].astype(int)\n",
    "predicted.to_csv(root + '/submission_keras.csv', index=False,quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "predicted.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
