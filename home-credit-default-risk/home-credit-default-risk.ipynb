{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import re\n",
    "import gc\n",
    "import sys, os, random\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(37)\n",
    "random.seed(17)\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "root = '/Users/schwalmdaniel/github/kaggle/home-credit-default-risk'\n",
    "#root = 'e:/kaggle/home-credit-default-risk'\n",
    "\n",
    "train=pd.read_csv(root + \"/application_train.csv\")\n",
    "test=pd.read_csv(root + \"/application_test.csv\")\n",
    "bureau=pd.read_csv(root + \"/bureau.csv\")\n",
    "previous_application=pd.read_csv(root + \"/previous_application.csv\")\n",
    "installments_payments=pd.read_csv(root + \"/installments_payments.csv\")\n",
    "bureau_balance=pd.read_csv(root + \"/bureau_balance.csv\")\n",
    "POS_CASH_balance=pd.read_csv(root + \"/POS_CASH_balance.csv\")\n",
    "credit_card_balance=pd.read_csv(root + \"/credit_card_balance.csv\")\n",
    "\n",
    "\n",
    "# have a look at the ds\n",
    "#train.head()\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_CASH_balance.head()\n",
    "\n",
    "num_aggregations = {\n",
    "        'CNT_INSTALMENT': ['min', 'max', 'mean','sum','var'],\n",
    "        'CNT_INSTALMENT_FUTURE': ['min', 'max', 'mean','sum','var'],\n",
    "        'SK_DPD': ['min', 'max', 'mean'],\n",
    "        'SK_DPD_DEF': ['min', 'max', 'mean'],\n",
    "    }\n",
    "\n",
    "POS_CASH_balance_cat, cat_cols = one_hot_encoder(POS_CASH_balance, nan_as_category= True)\n",
    "cat_aggregations = {}\n",
    "    \n",
    "for cat in cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "POS_CASH_balance_agg = POS_CASH_balance_cat.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "POS_CASH_balance_agg.columns = pd.Index(['POSBAL_' + e[0] + \"_\" + e[1].upper() for e in POS_CASH_balance_agg.columns.tolist()])\n",
    "\n",
    "train=train.join(POS_CASH_balance_agg,on='SK_ID_CURR', how='left')\n",
    "test=test.join(POS_CASH_balance_agg,on='SK_ID_CURR', how='left')\n",
    "\n",
    "del POS_CASH_balance_agg,POS_CASH_balance_cat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# without bureau balance it was 0.771, now it is 0.768. check if there is something TODO\n",
    "\n",
    "bureau_bal_joined  =bureau.merge(bureau_balance,on='SK_ID_BUREAU', how='left')\n",
    "bureau_bal_joined_red = bureau_bal_joined[['SK_ID_CURR','MONTHS_BALANCE','STATUS']]\n",
    "bureau_bal_joined_red['STATUS'].fillna('X',inplace=True)\n",
    "balance_mean = bureau_bal_joined_red['MONTHS_BALANCE'].mean()\n",
    "bureau_bal_joined_red['MONTHS_BALANCE'].fillna(balance_mean,inplace=True)\n",
    "\n",
    "bureau_bal_joined_red_cat, cat_cols = one_hot_encoder(bureau_bal_joined_red, nan_as_category= True)\n",
    "cat_aggregations = {}\n",
    "    \n",
    "for cat in cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "bureau_bal_joined_agg = bureau_bal_joined_red_cat.groupby('SK_ID_CURR').agg({**cat_aggregations})\n",
    "bureau_bal_joined_agg.columns = pd.Index(['BURBAL_' + e[0] + \"_\" + e[1].upper() for e in bureau_bal_joined_agg.columns.tolist()])\n",
    "\n",
    "train=train.join(bureau_bal_joined_agg,on='SK_ID_CURR', how='left')\n",
    "test=test.join(bureau_bal_joined_agg,on='SK_ID_CURR', how='left')\n",
    "\n",
    "del bureau_bal_joined_agg,bureau_bal_joined,bureau_bal_joined_red,bureau_bal_joined_red_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance.head()\n",
    "\n",
    "num_aggregations = {\n",
    "        'AMT_BALANCE': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['min', 'max', 'mean'],\n",
    "        'AMT_DRAWINGS_ATM_CURRENT': ['min', 'max', 'mean'],\n",
    "        'AMT_DRAWINGS_CURRENT': ['min', 'max', 'mean'],\n",
    "        'AMT_DRAWINGS_OTHER_CURRENT': ['min', 'max', 'mean'],\n",
    "        'AMT_DRAWINGS_POS_CURRENT': ['min', 'max', 'mean'],\n",
    "        'AMT_INST_MIN_REGULARITY': ['min', 'max', 'mean'],\n",
    "        'AMT_PAYMENT_CURRENT': ['min', 'max', 'mean'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': ['min', 'max', 'mean'],\n",
    "        'AMT_RECEIVABLE_PRINCIPAL': ['min', 'max', 'mean'],\n",
    "        'AMT_RECIVABLE': ['min', 'max', 'mean'],\n",
    "        'AMT_TOTAL_RECEIVABLE': ['min', 'max', 'mean'],\n",
    "        'CNT_DRAWINGS_ATM_CURRENT': ['min', 'max', 'mean','sum','var'],\n",
    "        'CNT_DRAWINGS_CURRENT': ['min', 'max', 'mean','sum','var'],\n",
    "        'CNT_DRAWINGS_OTHER_CURRENT': ['min', 'max', 'mean','sum','var'],\n",
    "        'CNT_DRAWINGS_POS_CURRENT': ['min', 'max', 'mean','sum','var'],\n",
    "        'CNT_INSTALMENT_MATURE_CUM': ['min', 'max', 'mean','sum','var'],\n",
    "        'SK_DPD': ['min', 'max', 'mean'],\n",
    "        'SK_DPD_DEF': ['min', 'max', 'mean'],\n",
    "    }\n",
    "\n",
    "credit_card_balance_cat, cat_cols = one_hot_encoder(credit_card_balance, nan_as_category= True)\n",
    "cat_aggregations = {}\n",
    "    \n",
    "for cat in cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "credit_card_balance_agg = credit_card_balance_cat.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "credit_card_balance_agg.columns = pd.Index(['CREBAL_' + e[0] + \"_\" + e[1].upper() for e in credit_card_balance_agg.columns.tolist()])\n",
    "\n",
    "train=train.join(credit_card_balance_agg,on='SK_ID_CURR', how='left')\n",
    "test=test.join(credit_card_balance_agg,on='SK_ID_CURR', how='left')\n",
    "\n",
    "del credit_card_balance_agg,credit_card_balance_cat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previous_application['CODE_REJECT_REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "prev_app_rejected = previous_application[(previous_application['CODE_REJECT_REASON'] != 'XAP')]\\\n",
    "    .groupby('SK_ID_CURR').CODE_REJECT_REASON.agg(['count']).reset_index()\n",
    "train=train.merge(prev_app_rejected,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(prev_app_rejected,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'count': 'prev_app_rejected_count'}, inplace=True)\n",
    "test.rename(columns={'count': 'prev_app_rejected_count'}, inplace=True)\n",
    "train['prev_app_rejected_count'].fillna(0,inplace=True)\n",
    "test['prev_app_rejected_count'].fillna(0,inplace=True)\n",
    "\n",
    "prev_app_applied_diff = previous_application[['SK_ID_CURR','AMT_APPLICATION','AMT_CREDIT']]\n",
    "prev_app_applied_diff['CREDIT_APPL_DIFF'] =  prev_app_applied_diff['AMT_CREDIT'] - \\\n",
    "    prev_app_applied_diff['AMT_APPLICATION'] \n",
    "\n",
    "prev_app_credit_diff = prev_app_applied_diff.groupby('SK_ID_CURR').\\\n",
    "    CREDIT_APPL_DIFF.agg(['min']).reset_index()\n",
    "train=train.merge(prev_app_credit_diff,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(prev_app_credit_diff,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'min': 'prev_app_credit_diff_min'}, inplace=True)\n",
    "                      #,'max': 'prev_app_credit_diff_max','mean': 'prev_app_credit_diff_mean'}\n",
    "                     \n",
    "test.rename(columns={'min': 'prev_app_credit_diff_min'}, inplace=True)\n",
    "                      #,'max': 'prev_app_credit_diff_max','mean': 'prev_app_credit_diff_mean'}\n",
    "                     #, inplace=True})\n",
    "train['prev_app_credit_diff_min'].fillna(0,inplace=True)\n",
    "#train['prev_app_credit_diff_max'].fillna(0,inplace=True)\n",
    "#train['prev_app_credit_diff_mean'].fillna(0,inplace=True)\n",
    "test['prev_app_credit_diff_min'].fillna(0,inplace=True)\n",
    "#test['prev_app_credit_diff_max'].fillna(0,inplace=True)\n",
    "#test['prev_app_credit_diff_mean'].fillna(0,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum','var'],\n",
    "    }\n",
    "\n",
    "prev_app_cat, cat_cols = one_hot_encoder(previous_application, nan_as_category= True)\n",
    "cat_aggregations = {}\n",
    "    \n",
    "for cat in cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "prev_agg = prev_app_cat.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "train=train.join(prev_agg,on='SK_ID_CURR', how='left')\n",
    "test=test.join(prev_agg,on='SK_ID_CURR', how='left')\n",
    "\n",
    "del prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aggregations = {\n",
    "        'DAYS_PAYMENT_DIFF': ['min', 'max', 'mean'],\n",
    "        'PAYMENT_DIFF': ['min', 'max', 'mean'],\n",
    "        'AMT_PAYMENT': [ 'mean'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['mean'],\n",
    "    }\n",
    "\n",
    "ins_pay = installments_payments.drop(['SK_ID_PREV','NUM_INSTALMENT_VERSION','NUM_INSTALMENT_NUMBER'],axis=1)\n",
    "ins_pay['DAYS_PAYMENT_DIFF'] = ins_pay['DAYS_INSTALMENT'] - ins_pay['DAYS_ENTRY_PAYMENT']\n",
    "ins_pay['PAYMENT_DIFF'] = ins_pay['AMT_INSTALMENT'] - ins_pay['AMT_PAYMENT']\n",
    "\n",
    "ins_pay_agg = ins_pay.groupby('SK_ID_CURR').agg({**num_aggregations})\n",
    "ins_pay_agg.columns = pd.Index(['INS_' + e[0] + \"_\" + e[1].upper() for e in ins_pay_agg.columns.tolist()])\n",
    "\n",
    "ins_pay_agg.head()\n",
    "train=train.join(ins_pay_agg,on='SK_ID_CURR', how='left')\n",
    "test=test.join(ins_pay_agg,on='SK_ID_CURR', how='left')\n",
    "\n",
    "del ins_pay_agg, ins_pay"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureaue_active_credit_limit = bureau[(bureau['CREDIT_ACTIVE'] == 'Active') & (bureau['AMT_CREDIT_SUM_LIMIT'].notnull())\\\n",
    "            & (bureau['AMT_CREDIT_SUM_LIMIT'] > 0.0)]\\\n",
    "    .groupby('SK_ID_CURR').AMT_CREDIT_SUM_LIMIT.agg(['sum']).reset_index()\n",
    "\n",
    "bureau_last_credit_update_active = bureau[(bureau['CREDIT_ACTIVE'] == 'Active')]\\\n",
    "    .groupby('SK_ID_CURR').DAYS_CREDIT_UPDATE.agg(['min','max']).reset_index()\n",
    "bureau_last_credit_update_closed = bureau[(bureau['CREDIT_ACTIVE'] == 'Closed')]\\\n",
    "    .groupby('SK_ID_CURR').DAYS_CREDIT_UPDATE.agg(['min','max']).reset_index()\n",
    "bureau_last_credit_update = bureau.groupby('SK_ID_CURR').DAYS_CREDIT_UPDATE.agg(['min','max']).reset_index()\n",
    "\n",
    "train=train.merge(bureau_last_credit_update_active,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_last_credit_update_active,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'max': 'bureau_last_credit_update_active_max',\n",
    "                      'min': 'bureau_last_credit_update_active_min'}, inplace=True)\n",
    "test.rename(columns={'max': 'bureau_last_credit_update_active_max',\n",
    "                     'min': 'bureau_last_credit_update_active_min'}, inplace=True)\n",
    "train['bureau_last_credit_update_active_max'].fillna(0,inplace=True)\n",
    "train['bureau_last_credit_update_active_min'].fillna(0,inplace=True)\n",
    "test['bureau_last_credit_update_active_max'].fillna(0,inplace=True)\n",
    "test['bureau_last_credit_update_active_min'].fillna(0,inplace=True)\n",
    "\n",
    "train=train.merge(bureau_last_credit_update_closed,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_last_credit_update_closed,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'max': 'bureau_last_credit_update_closed_max',\n",
    "                      'min': 'bureau_last_credit_update_closed_min'}, inplace=True)\n",
    "test.rename(columns={'max': 'bureau_last_credit_update_closed_max',\n",
    "                     'min': 'bureau_last_credit_update_closed_min'}, inplace=True)\n",
    "train['bureau_last_credit_update_closed_max'].fillna(0,inplace=True)\n",
    "train['bureau_last_credit_update_closed_min'].fillna(0,inplace=True)\n",
    "test['bureau_last_credit_update_closed_max'].fillna(0,inplace=True)\n",
    "test['bureau_last_credit_update_closed_min'].fillna(0,inplace=True)\n",
    "\n",
    "train=train.merge(bureau_last_credit_update,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_last_credit_update,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'max': 'bureau_last_credit_update_max',\n",
    "                      'min': 'bureau_last_credit_update_min'}, inplace=True)\n",
    "test.rename(columns={'max': 'bureau_last_credit_update_max',\n",
    "                     'min': 'bureau_last_credit_update_min'}, inplace=True)\n",
    "train['bureau_last_credit_update_max'].fillna(0,inplace=True)\n",
    "train['bureau_last_credit_update_min'].fillna(0,inplace=True)\n",
    "test['bureau_last_credit_update_max'].fillna(0,inplace=True)\n",
    "test['bureau_last_credit_update_min'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ax1 = sns.distplot(train[\"WEEKDAY_APPR_PROCESS_START\"][train.TARGET==1], color='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>bureau_max_overdue_min</th>\n",
       "      <th>bureau_max_overdue_max</th>\n",
       "      <th>bureau_credit_prolong_min</th>\n",
       "      <th>bureau_credit_prolong_max</th>\n",
       "      <th>bureau_credit_prolong_mean</th>\n",
       "      <th>bureau_credit_prolong_std</th>\n",
       "      <th>bureau_credit_overdue_min</th>\n",
       "      <th>bureau_credit_overdue_max</th>\n",
       "      <th>bureau_credit_overdue_mean</th>\n",
       "      <th>bureau_credit_overdue_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5043.645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "             ...              bureau_max_overdue_min bureau_max_overdue_max  \\\n",
       "0            ...                                 0.0               5043.645   \n",
       "1            ...                                 0.0                  0.000   \n",
       "2            ...                                 0.0                  0.000   \n",
       "3            ...                                 0.0                  0.000   \n",
       "4            ...                                 0.0                  0.000   \n",
       "\n",
       "  bureau_credit_prolong_min bureau_credit_prolong_max  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "  bureau_credit_prolong_mean bureau_credit_prolong_std  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   bureau_credit_overdue_min  bureau_credit_overdue_max  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   bureau_credit_overdue_mean  bureau_credit_overdue_std  \n",
       "0                         0.0                        0.0  \n",
       "1                         0.0                        0.0  \n",
       "2                         0.0                        0.0  \n",
       "3                         0.0                        0.0  \n",
       "4                         0.0                        0.0  \n",
       "\n",
       "[5 rows x 455 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_credit = pd.DataFrame(bureau[['SK_ID_CURR', 'CREDIT_ACTIVE']])\n",
    "\n",
    "bureau_overdue = pd.DataFrame(bureau[['SK_ID_CURR', 'CREDIT_DAY_OVERDUE']])\n",
    "bureau_credit_type = pd.DataFrame(bureau[['SK_ID_CURR', 'CREDIT_ACTIVE','CREDIT_TYPE']])\n",
    "bureau_sum_debt = pd.DataFrame(bureau[['SK_ID_CURR', 'CREDIT_ACTIVE','AMT_CREDIT_SUM_DEBT']])\n",
    "\n",
    "bureau_credit_active = bureau_credit[bureau_credit['CREDIT_ACTIVE'] == 'Active'].\\\n",
    "    groupby('SK_ID_CURR').CREDIT_ACTIVE.agg(['count']).reset_index()\n",
    "bureau_credit_closed = bureau_credit[bureau_credit['CREDIT_ACTIVE'] == 'Closed'].\\\n",
    "    groupby('SK_ID_CURR').CREDIT_ACTIVE.agg(['count']).reset_index()\n",
    "bureau_credit_type_active = bureau_credit_type[bureau_credit_type['CREDIT_ACTIVE'] == 'Active'].\\\n",
    "    groupby('SK_ID_CURR').CREDIT_TYPE.agg(['count']).reset_index()\n",
    "bureau_credit_type_closed = bureau_credit_type[bureau_credit_type['CREDIT_ACTIVE'] == 'Closed'].\\\n",
    "    groupby('SK_ID_CURR').CREDIT_TYPE.agg(['count']).reset_index()\n",
    "bureau_sum_debt_active = bureau_sum_debt[bureau_sum_debt['CREDIT_ACTIVE'] == 'Active'].\\\n",
    "    groupby('SK_ID_CURR').AMT_CREDIT_SUM_DEBT.agg(['sum']).reset_index()\n",
    "bureau_sum_debt_closed = bureau_sum_debt[bureau_sum_debt['CREDIT_ACTIVE'] == 'Closed'].\\\n",
    "    groupby('SK_ID_CURR').AMT_CREDIT_SUM_DEBT.agg(['sum']).reset_index()\n",
    "bureau_credit_overdue = bureau_overdue.groupby('SK_ID_CURR').CREDIT_DAY_OVERDUE.agg([\n",
    "        'min', \n",
    "        'max', \n",
    "        'mean', \n",
    "        'std']).reset_index()\n",
    "bureau_credit_overdue.fillna(0,inplace=True)\n",
    "bureau_credit_prolong = pd.DataFrame(bureau[['SK_ID_CURR', 'CNT_CREDIT_PROLONG']])\\\n",
    "    .groupby('SK_ID_CURR').CNT_CREDIT_PROLONG.agg([\n",
    "        'min', \n",
    "        'max', \n",
    "        'mean', \n",
    "        'std']).reset_index()\n",
    "bureau_currency_count = pd.DataFrame(bureau[['SK_ID_CURR', 'CREDIT_CURRENCY']])\\\n",
    "    .groupby('SK_ID_CURR').CREDIT_CURRENCY.agg(['count']).reset_index()\n",
    "bureau_sum_overdue = pd.DataFrame(bureau[['SK_ID_CURR', 'AMT_CREDIT_SUM_OVERDUE']])\\\n",
    "    .groupby('SK_ID_CURR').AMT_CREDIT_SUM_OVERDUE.agg(['sum']).reset_index()\n",
    "bureau_sum_overdue.fillna(0,inplace=True)\n",
    "bureau_max_overdue = pd.DataFrame(bureau[['SK_ID_CURR', 'AMT_CREDIT_MAX_OVERDUE']])\\\n",
    "    .groupby('SK_ID_CURR').AMT_CREDIT_MAX_OVERDUE.agg(['min','max']).reset_index()\n",
    "bureau_max_overdue.fillna(0,inplace=True)\n",
    "bureau_credit_active_enddate = bureau[bureau['CREDIT_ACTIVE'] == 'Active'].\\\n",
    "    groupby('SK_ID_CURR').DAYS_CREDIT_ENDDATE.agg(['max','min','mean']).reset_index()\n",
    "bureau_credit_closed_enddate = bureau[bureau['CREDIT_ACTIVE'] == 'Closed'].\\\n",
    "    groupby('SK_ID_CURR').DAYS_CREDIT_ENDDATE.agg(['max','min','mean']).reset_index()\n",
    "\n",
    "    \n",
    "train=train.merge(bureaue_active_credit_limit,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureaue_active_credit_limit,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'sum': 'bureaue_active_credit_limit'}, inplace=True)\n",
    "test.rename(columns={'sum': 'bureaue_active_credit_limit'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_credit_active_enddate,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_active_enddate,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'max': 'bureau_credit_active_enddate_max','min': 'bureau_credit_active_enddate_min',\n",
    "                     'mean': 'bureau_credit_active_enddate_mean',}, inplace=True)\n",
    "test.rename(columns={'max': 'bureau_credit_active_enddate_max','min': 'bureau_credit_active_enddate_min',\n",
    "                     'mean': 'bureau_credit_active_enddate_mean',}, inplace=True)\n",
    "train=train.merge(bureau_credit_closed_enddate,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_closed_enddate,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'max': 'bureau_credit_closed_enddate_max','min': 'bureau_credit_closed_enddate_min',\n",
    "                     'mean': 'bureau_credit_closed_enddate_mean',}, inplace=True)\n",
    "test.rename(columns={'max': 'bureau_credit_closed_enddate_max','min': 'bureau_credit_closed_enddate_min',\n",
    "                     'mean': 'bureau_credit_closed_enddate_mean',}, inplace=True)\n",
    "train['bureau_credit_active_enddate_max'].fillna(0,inplace=True)\n",
    "train['bureau_credit_active_enddate_min'].fillna(0,inplace=True)\n",
    "train['bureau_credit_active_enddate_mean'].fillna(0,inplace=True)\n",
    "train['bureau_credit_closed_enddate_max'].fillna(0,inplace=True)\n",
    "train['bureau_credit_closed_enddate_min'].fillna(0,inplace=True)\n",
    "train['bureau_credit_closed_enddate_mean'].fillna(0,inplace=True)\n",
    "test['bureau_credit_active_enddate_max'].fillna(0,inplace=True)\n",
    "test['bureau_credit_active_enddate_min'].fillna(0,inplace=True)\n",
    "test['bureau_credit_active_enddate_mean'].fillna(0,inplace=True)\n",
    "test['bureau_credit_closed_enddate_max'].fillna(0,inplace=True)\n",
    "test['bureau_credit_closed_enddate_min'].fillna(0,inplace=True)\n",
    "test['bureau_credit_closed_enddate_mean'].fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "train=train.merge(bureau_credit_active,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_active,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'count': 'bureau_credit_active_count'}, inplace=True)\n",
    "test.rename(columns={'count': 'bureau_credit_active_count'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_credit_closed,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_closed,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'count': 'bureau_credit_closed_count'}, inplace=True)\n",
    "test.rename(columns={'count': 'bureau_credit_closed_count'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_credit_type_active,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_type_active,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'count': 'bureau_credit_type_active_count'}, inplace=True)\n",
    "test.rename(columns={'count': 'bureau_credit_type_active_count'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_credit_type_closed,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_type_closed,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'count': 'bureau_credit_type_closed_count'}, inplace=True)\n",
    "test.rename(columns={'count': 'bureau_credit_type_closed_count'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_sum_debt_active,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_sum_debt_active,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'sum': 'bureau_sum_debt_active_sum'}, inplace=True)\n",
    "test.rename(columns={'sum': 'bureau_sum_debt_active_sum'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_sum_debt_closed,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_sum_debt_closed,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'sum': 'bureau_sum_debt_closed_sum'}, inplace=True)\n",
    "test.rename(columns={'sum': 'bureau_sum_debt_closed_sum'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_currency_count,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_currency_count,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'count': 'bureau_currency_count'}, inplace=True)\n",
    "test.rename(columns={'count': 'bureau_currency_count'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_sum_overdue,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_sum_overdue,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'sum': 'bureau_sum_overdue'}, inplace=True)\n",
    "test.rename(columns={'sum': 'bureau_sum_overdue'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_max_overdue,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_max_overdue,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'max': 'bureau_max_overdue_max','min': 'bureau_max_overdue_min'}, inplace=True)\n",
    "test.rename(columns={'max': 'bureau_max_overdue_max','min': 'bureau_max_overdue_min'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_credit_prolong,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_prolong,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'min': 'bureau_credit_prolong_min','max': 'bureau_credit_prolong_max',\n",
    "                      'mean': 'bureau_credit_prolong_mean','std': 'bureau_credit_prolong_std'}, inplace=True)\n",
    "test.rename(columns={'min': 'bureau_credit_prolong_min','max': 'bureau_credit_prolong_max',\n",
    "                      'mean': 'bureau_credit_prolong_mean','std': 'bureau_credit_prolong_std'}, inplace=True)\n",
    "\n",
    "train=train.merge(bureau_credit_overdue,on='SK_ID_CURR', how='left')\n",
    "test=test.merge(bureau_credit_overdue,on='SK_ID_CURR', how='left')\n",
    "train.rename(columns={'min': 'bureau_credit_overdue_min','max': 'bureau_credit_overdue_max',\n",
    "                      'mean': 'bureau_credit_overdue_mean','std': 'bureau_credit_overdue_std'}, inplace=True)\n",
    "test.rename(columns={'min': 'bureau_credit_overdue_min','max': 'bureau_credit_overdue_max',\n",
    "                      'mean': 'bureau_credit_overdue_mean','std': 'bureau_credit_overdue_std'}, inplace=True)\n",
    "train['bureau_credit_overdue_min'].fillna(0,inplace=True)\n",
    "train['bureau_credit_overdue_max'].fillna(0,inplace=True)\n",
    "train['bureau_credit_overdue_mean'].fillna(0,inplace=True)\n",
    "train['bureau_credit_overdue_std'].fillna(0,inplace=True)\n",
    "train['bureau_credit_prolong_min'].fillna(0,inplace=True)\n",
    "train['bureau_credit_prolong_max'].fillna(0,inplace=True)\n",
    "train['bureau_credit_prolong_mean'].fillna(0,inplace=True)\n",
    "train['bureau_credit_prolong_std'].fillna(0,inplace=True)\n",
    "train['bureau_credit_active_count'].fillna(0,inplace=True)\n",
    "train['bureau_credit_closed_count'].fillna(0,inplace=True)\n",
    "train['bureau_sum_debt_active_sum'].fillna(0,inplace=True)\n",
    "train['bureau_sum_debt_closed_sum'].fillna(0,inplace=True)\n",
    "train['bureau_credit_type_active_count'].fillna(0,inplace=True)\n",
    "train['bureau_credit_type_closed_count'].fillna(0,inplace=True)\n",
    "train['bureau_currency_count'].fillna(0,inplace=True)\n",
    "train['bureau_sum_overdue'].fillna(0,inplace=True)\n",
    "train['bureau_max_overdue_max'].fillna(0,inplace=True)\n",
    "train['bureau_max_overdue_min'].fillna(0,inplace=True)\n",
    "train['bureaue_active_credit_limit'].fillna(0,inplace=True)\n",
    "test['bureau_credit_overdue_min'].fillna(0,inplace=True)\n",
    "test['bureau_credit_overdue_max'].fillna(0,inplace=True)\n",
    "test['bureau_credit_overdue_mean'].fillna(0,inplace=True)\n",
    "test['bureau_credit_overdue_std'].fillna(0,inplace=True)\n",
    "test['bureau_credit_prolong_min'].fillna(0,inplace=True)\n",
    "test['bureau_credit_prolong_max'].fillna(0,inplace=True)\n",
    "test['bureau_credit_prolong_mean'].fillna(0,inplace=True)\n",
    "test['bureau_credit_prolong_std'].fillna(0,inplace=True)\n",
    "test['bureau_credit_active_count'].fillna(0,inplace=True)\n",
    "test['bureau_credit_closed_count'].fillna(0,inplace=True)\n",
    "test['bureau_sum_debt_active_sum'].fillna(0,inplace=True)\n",
    "test['bureau_sum_debt_closed_sum'].fillna(0,inplace=True)\n",
    "test['bureau_credit_type_active_count'].fillna(0,inplace=True)\n",
    "test['bureau_credit_type_closed_count'].fillna(0,inplace=True)\n",
    "test['bureau_currency_count'].fillna(0,inplace=True)\n",
    "test['bureau_sum_overdue'].fillna(0,inplace=True)\n",
    "test['bureau_max_overdue_max'].fillna(0,inplace=True)\n",
    "test['bureau_max_overdue_min'].fillna(0,inplace=True)\n",
    "test['bureaue_active_credit_limit'].fillna(0,inplace=True)\n",
    "\n",
    "train.head()\n",
    "                            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bureau_credit_prolong['mean'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train['TARGET'].value_counts()\n",
    "\n",
    "# it is an unbalanced data, 8.5% of the target is 1, so the baseline is around 92%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train['NAME_FAMILY_STATUS'].value_counts()\n",
    "train['FAMILY_STATUS_SINGLE'] = train['NAME_FAMILY_STATUS']\\\n",
    "    .apply(lambda x: 1 if x in ['Single / not married','Separated','Widow'] else 0)\n",
    "test['FAMILY_STATUS_SINGLE'] = test['NAME_FAMILY_STATUS']\\\n",
    "    .apply(lambda x: 1 if x in ['Single / not married','Separated','Widow'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NAME_CONTRACT_TYPE', 2 values, converting to 0/1\n",
    "train['NAME_CONTRACT_TYPE'] = train['NAME_CONTRACT_TYPE'].apply(lambda x: 0 if x == 'Cash loans' else 1)\n",
    "test['NAME_CONTRACT_TYPE'] = test['NAME_CONTRACT_TYPE'].apply(lambda x: 0 if x == 'Cash loans' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CODE_GENDER', drop XNA as only 4 rows, convert the rest to 0/1\n",
    "train = train[train['CODE_GENDER'] != 'XNA']\n",
    "train['CODE_GENDER'] = train['CODE_GENDER'].apply(lambda x: 0 if x == 'F' else 1)\n",
    "test['CODE_GENDER'] = test['CODE_GENDER'].apply(lambda x: 0 if x == 'F' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAG_OWN_CAR\n",
    "train['FLAG_OWN_CAR'] = train['FLAG_OWN_CAR'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "test['FLAG_OWN_CAR'] = test['FLAG_OWN_CAR'].apply(lambda x: 1 if x == 'Y' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAG_OWN_REALTY\n",
    "train['FLAG_OWN_REALTY'] = train['FLAG_OWN_REALTY'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "test['FLAG_OWN_REALTY'] = test['FLAG_OWN_REALTY'].apply(lambda x: 1 if x == 'Y' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where null it should be dropped or mean or average income/annuity\n",
    "\n",
    "avgAnnuityRate = (train['AMT_ANNUITY']/train['AMT_CREDIT']).mean()\n",
    "train['AMT_ANNUITY'].fillna(avgAnnuityRate * train['AMT_CREDIT'],inplace=True)\n",
    "test['AMT_ANNUITY'].fillna(avgAnnuityRate * train['AMT_CREDIT'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  where null mean or average income / goods price\n",
    "goodsPriceMean = train['AMT_GOODS_PRICE'].mean()\n",
    "train['AMT_GOODS_PRICE'].fillna(goodsPriceMean,inplace=True)\n",
    "test['AMT_GOODS_PRICE'].fillna(goodsPriceMean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  categorical, dummify, where null either unknown or most frequent\n",
    "train['NAME_TYPE_SUITE'].fillna('Unaccompanied',inplace=True)\n",
    "test['NAME_TYPE_SUITE'].fillna('Unaccompanied',inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# convert days to years\n",
    "train['DAYS_BIRTH'] = train['DAYS_BIRTH'] / -365\n",
    "test['DAYS_BIRTH'] = test['DAYS_BIRTH'] / -365"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# numeric\n",
    "train['REGION_POPULATION_RELATIVE'].hist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: negative, numeric\n",
    "train['DAYS_BIRTH'].hist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: negative, numeric\n",
    "train['DAYS_EMPLOYED'].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: negative, numeric\n",
    "train['DAYS_REGISTRATION'].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TODO: negative, numeric\n",
    "train['DAYS_ID_PUBLISH'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric, the older the worse, where null check own car\n",
    "train['OWN_CAR_AGE'].fillna(100,inplace=True)\n",
    "test['OWN_CAR_AGE'].fillna(100,inplace=True)\n",
    "train['OWN_CAR_AGE'] = train['OWN_CAR_AGE'] * -1\n",
    "test['OWN_CAR_AGE'] = test['OWN_CAR_AGE'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric, drop where it is null\n",
    "train = train[train['CNT_FAM_MEMBERS'] > 0]\n",
    "test = test[test['CNT_FAM_MEMBERS'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.columns.tolist()\n",
    "train['INCOME_ANNUITY_RATIO'] = train['AMT_ANNUITY'] / train['AMT_INCOME_TOTAL']\n",
    "test['INCOME_ANNUITY_RATIO'] = test['AMT_ANNUITY'] / test['AMT_INCOME_TOTAL']\n",
    "\n",
    "train['INCOME_CREDIT_RATIO'] = train['AMT_CREDIT'] / train['AMT_INCOME_TOTAL']\n",
    "test['INCOME_CREDIT_RATIO'] = test['AMT_CREDIT'] / test['AMT_INCOME_TOTAL']\n",
    "\n",
    "train['ANNUITY_CREDIT_RATIO'] = train['AMT_CREDIT'] / train['AMT_ANNUITY']\n",
    "test['ANNUITY_CREDIT_RATIO'] = test['AMT_CREDIT'] / test['AMT_ANNUITY']\n",
    "\n",
    "train['GOODS_CREDIT_RATIO'] = train['AMT_CREDIT'] / train['AMT_GOODS_PRICE']\n",
    "test['GOODS_CREDIT_RATIO'] = test['AMT_CREDIT'] / test['AMT_GOODS_PRICE']\n",
    "\n",
    "train['INCOME_PER_CAPITA'] = train['AMT_INCOME_TOTAL'] / train['CNT_FAM_MEMBERS']\n",
    "test['INCOME_PER_CAPITA'] = test['AMT_INCOME_TOTAL'] / test['CNT_FAM_MEMBERS']\n",
    "\n",
    "train['EXT_SOURCES_MEAN'] = train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "test['EXT_SOURCES_MEAN'] = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "\n",
    "train['EXT_SOURCES_PROD'] = train['EXT_SOURCE_1'] * train['EXT_SOURCE_2'] * train['EXT_SOURCE_3']\n",
    "test['EXT_SOURCES_PROD'] = test['EXT_SOURCE_1'] * test['EXT_SOURCE_2'] * test['EXT_SOURCE_3']\n",
    "\n",
    "train['EXT_SCORES_STD'] = train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "train['EXT_SCORES_STD'] = train['EXT_SCORES_STD'].fillna(train['EXT_SCORES_STD'].mean())\n",
    "test['EXT_SCORES_STD'] = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "test['EXT_SCORES_STD'] = test['EXT_SCORES_STD'].fillna(train['EXT_SCORES_STD'].mean())\n",
    "\n",
    "train['EMPLOY_TO_BIRTH_RATIO'] = train['DAYS_EMPLOYED'] / train['DAYS_BIRTH']\n",
    "test['EMPLOY_TO_BIRTH_RATIO'] = test['DAYS_EMPLOYED'] / test['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null with mean for _1, _2, _3\n",
    "'''mean1 = train['EXT_SOURCE_1'].mean()\n",
    "mean2 = train['EXT_SOURCE_2'].mean()\n",
    "mean3 = train['EXT_SOURCE_3'].mean()\n",
    "train['EXT_SOURCE_1'].fillna(mean1,inplace=True)\n",
    "train['EXT_SOURCE_2'].fillna(mean2,inplace=True)\n",
    "train['EXT_SOURCE_3'].fillna(mean3,inplace=True)\n",
    "test['EXT_SOURCE_1'].fillna(mean1,inplace=True)\n",
    "test['EXT_SOURCE_2'].fillna(mean2,inplace=True)\n",
    "test['EXT_SOURCE_3'].fillna(mean3,inplace=True)'''\n",
    "train['EXT_SOURCE_1'].fillna(0,inplace=True)\n",
    "train['EXT_SOURCE_2'].fillna(0,inplace=True)\n",
    "train['EXT_SOURCE_3'].fillna(0,inplace=True)\n",
    "test['EXT_SOURCE_1'].fillna(0,inplace=True)\n",
    "test['EXT_SOURCE_2'].fillna(0,inplace=True)\n",
    "test['EXT_SOURCE_3'].fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with mean all _AVG, _MEDI, _MODE\n",
    "for col in train.columns.tolist():\n",
    "    if (col.endswith('_AVG') or col.endswith('_MEDI') or col.endswith('_MODE')) and col not in ['FONDKAPREMONT_MODE','HOUSETYPE_MODE',\n",
    "                    'WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE']: \n",
    "        #print (col)\n",
    "        mean = train[col].mean()\n",
    "        train[col].fillna(mean,inplace=True)\n",
    "        test[col].fillna(mean,inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMERGENCYSTATE_MODE\n",
    "train['EMERGENCYSTATE_MODE'] = train['EMERGENCYSTATE_MODE'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "test['EMERGENCYSTATE_MODE'] = test['EMERGENCYSTATE_MODE'].apply(lambda x: 1 if x == 'Y' else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fill none with mean or median for all circle\n",
    "for col in train.columns.tolist():\n",
    "    if col.endswith('_CIRCLE'):\n",
    "        mean = train[col].mean()\n",
    "        train[col].fillna(mean,inplace=True)\n",
    "        test[col].fillna(mean,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative numeric, drop where it is null\n",
    "train['DAYS_LAST_PHONE_CHANGE'].fillna(0,inplace=True)\n",
    "test['DAYS_LAST_PHONE_CHANGE'].fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all amt_credit req, maybe bin it\n",
    "train['AMT_REQ_CREDIT_BUREAU_YEAR'].mean()\n",
    "\n",
    "for col in train.columns.tolist():\n",
    "    if 'AMT_REQ_CREDIT_BUREAU_' in col:\n",
    "        #print (col)\n",
    "        mean = train[col].mean()\n",
    "        train[col].fillna(mean,inplace=True)\n",
    "        test[col].fillna(mean,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 461)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307505, 573)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_objs_num = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "dataset = pd.get_dummies(dataset, \n",
    "    columns = ['NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE',\n",
    "            'OCCUPATION_TYPE','ORGANIZATION_TYPE','FONDKAPREMONT_MODE',\n",
    "            'HOUSETYPE_MODE','WALLSMATERIAL_MODE'],prefix_sep='__') # ,'WEEKDAY_APPR_PROCESS_START'\n",
    "train = dataset[:train_objs_num]\n",
    "test = dataset[train_objs_num:]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correlations = train.corr()['TARGET'].sort_values()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train['FLAG_CONT_MOBILE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "low_correlation_cols = ['ORGANIZATION_TYPE__Trade: type 5','ORGANIZATION_TYPE__Transport: type 2',\n",
    "                        'NONLIVINGAPARTMENTS_MODE','FLAG_DOCUMENT_12','ORGANIZATION_TYPE__Telecom',\n",
    "                        'ORGANIZATION_TYPE__Industry: type 6','bureau_credit_prolong_min','ORGANIZATION_TYPE__Housing',\n",
    "                        'OCCUPATION_TYPE__Realty agents','NAME_HOUSING_TYPE__Co-op apartment','FLAG_DOCUMENT_5',\n",
    "                        'ORGANIZATION_TYPE__Legal Services','ORGANIZATION_TYPE__Industry: type 7',\n",
    "                        'ORGANIZATION_TYPE__Advertising','FLAG_DOCUMENT_20',\n",
    "                        'ORGANIZATION_TYPE__Business Entity Type 1','FLAG_CONT_MOBILE',\n",
    "                        'NAME_TYPE_SUITE__Group of people','FLAG_MOBIL','WALLSMATERIAL_MODE__Others',\n",
    "                        'AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_HOUR','HOUSETYPE_MODE__terraced house',\n",
    "                       'WEEKDAY_APPR_PROCESS_START']\n",
    "\n",
    "X = train.drop(['SK_ID_CURR','TARGET'] + low_correlation_cols, axis=1)\n",
    "y = train['TARGET']\n",
    "X_test = test.drop(['SK_ID_CURR','TARGET'] + low_correlation_cols, axis=1)\n",
    "\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trainx = train.drop(['SK_ID_CURR'] + low_correlation_cols, axis=1)\n",
    "correlations = trainx.corr()['TARGET'].sort_values()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:60: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:62: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.743081\n",
      "[200]\tvalid_0's auc: 0.760908\n",
      "[300]\tvalid_0's auc: 0.772196\n",
      "[400]\tvalid_0's auc: 0.777391\n",
      "[500]\tvalid_0's auc: 0.780043\n",
      "[600]\tvalid_0's auc: 0.78166\n",
      "[700]\tvalid_0's auc: 0.782774\n",
      "[800]\tvalid_0's auc: 0.783349\n",
      "[900]\tvalid_0's auc: 0.783811\n",
      "[1000]\tvalid_0's auc: 0.784056\n",
      "[1100]\tvalid_0's auc: 0.78431\n",
      "[1200]\tvalid_0's auc: 0.784559\n",
      "[1300]\tvalid_0's auc: 0.78461\n",
      "[1400]\tvalid_0's auc: 0.784558\n",
      "Early stopping, best iteration is:\n",
      "[1347]\tvalid_0's auc: 0.784612\n",
      "Important features:\n",
      "[('EXT_SOURCES_MEAN', 1112), ('ANNUITY_CREDIT_RATIO', 1017), ('DAYS_BIRTH', 860), ('GOODS_CREDIT_RATIO', 670), ('EXT_SOURCE_3', 663), ('EXT_SOURCE_2', 584), ('AMT_ANNUITY', 577), ('INS_AMT_PAYMENT_MEAN', 568), ('INS_PAYMENT_DIFF_MEAN', 558), ('DAYS_ID_PUBLISH', 549), ('POSBAL_CNT_INSTALMENT_FUTURE_MEAN', 541), ('INCOME_ANNUITY_RATIO', 470), ('bureau_sum_debt_active_sum', 445), ('DAYS_REGISTRATION', 440), ('POSBAL_CNT_INSTALMENT_SUM', 428), ('POSBAL_CNT_INSTALMENT_FUTURE_VAR', 425), ('INS_DAYS_ENTRY_PAYMENT_MEAN', 423), ('bureau_credit_active_enddate_min', 407), ('EXT_SOURCE_1', 407), ('INS_DAYS_PAYMENT_DIFF_MEAN', 401), ('EMPLOY_TO_BIRTH_RATIO', 400), ('INS_DAYS_PAYMENT_DIFF_MIN', 398), ('PREV_CNT_PAYMENT_MEAN', 391), ('bureau_credit_active_enddate_max', 387), ('PREV_DAYS_DECISION_MAX', 377), ('DAYS_LAST_PHONE_CHANGE', 370), ('POSBAL_NAME_CONTRACT_STATUS_Active_MEAN', 361), ('INCOME_CREDIT_RATIO', 335), ('REGION_POPULATION_RELATIVE', 332), ('PREV_DAYS_DECISION_MIN', 327), ('bureau_last_credit_update_max', 311), ('PREV_AMT_ANNUITY_MIN', 304), ('INS_DAYS_PAYMENT_DIFF_MAX', 304), ('AMT_GOODS_PRICE', 294), ('PREV_DAYS_DECISION_MEAN', 293), ('AMT_CREDIT', 293), ('DAYS_EMPLOYED', 286), ('INCOME_PER_CAPITA', 274), ('PREV_AMT_DOWN_PAYMENT_MAX', 273), ('bureau_credit_active_enddate_mean', 272), ('PREV_AMT_ANNUITY_MEAN', 269), ('bureau_max_overdue_max', 265), ('bureau_credit_closed_enddate_max', 263), ('CODE_GENDER', 257), ('POSBAL_CNT_INSTALMENT_VAR', 255), ('PREV_NAME_CONTRACT_STATUS_Refused_MEAN', 254), ('PREV_RATE_DOWN_PAYMENT_MAX', 251), ('bureau_last_credit_update_closed_max', 250), ('PREV_AMT_GOODS_PRICE_MIN', 247), ('PREV_AMT_ANNUITY_MAX', 240), ('bureau_credit_active_count', 237), ('bureau_last_credit_update_active_min', 235), ('prev_app_credit_diff_min', 234), ('INS_PAYMENT_DIFF_MAX', 229), ('POSBAL_SK_DPD_DEF_MEAN', 228), ('bureau_last_credit_update_active_max', 226), ('OWN_CAR_AGE', 225), ('POSBAL_CNT_INSTALMENT_FUTURE_SUM', 220), ('PREV_NAME_YIELD_GROUP_high_MEAN', 209), ('POSBAL_NAME_CONTRACT_STATUS_Completed_MEAN', 209), ('PREV_NAME_YIELD_GROUP_middle_MEAN', 206), ('CREBAL_CNT_DRAWINGS_ATM_CURRENT_MEAN', 205), ('PREV_NAME_CONTRACT_STATUS_Approved_MEAN', 203), ('bureau_credit_closed_enddate_mean', 199), ('AMT_INCOME_TOTAL', 199), ('PREV_NAME_TYPE_SUITE_nan_MEAN', 198), ('PREV_RATE_DOWN_PAYMENT_MEAN', 194), ('PREV_AMT_DOWN_PAYMENT_MEAN', 193), ('bureau_credit_closed_enddate_min', 187), ('PREV_WEEKDAY_APPR_PROCESS_START_THURSDAY_MEAN', 186), ('PREV_WEEKDAY_APPR_PROCESS_START_FRIDAY_MEAN', 184), ('PREV_AMT_APPLICATION_MEAN', 176), ('PREV_NAME_TYPE_SUITE_Unaccompanied_MEAN', 170), ('HOUR_APPR_PROCESS_START', 169), ('CREBAL_CNT_DRAWINGS_CURRENT_VAR', 169), ('BURBAL_STATUS_0_MEAN', 169), ('bureaue_active_credit_limit', 168), ('PREV_CNT_PAYMENT_SUM', 164), ('PREV_AMT_CREDIT_MEAN', 161), ('BURBAL_STATUS_X_MEAN', 161), ('POSBAL_CNT_INSTALMENT_MEAN', 159), ('bureau_last_credit_update_min', 157), ('PREV_AMT_GOODS_PRICE_MEAN', 155), ('BURBAL_STATUS_C_MEAN', 153), ('PREV_NAME_YIELD_GROUP_low_normal_MEAN', 152), ('PREV_NAME_CLIENT_TYPE_New_MEAN', 151), ('BURBAL_STATUS_1_MEAN', 149), ('PREV_AMT_CREDIT_MAX', 148), ('PREV_WEEKDAY_APPR_PROCESS_START_TUESDAY_MEAN', 147), ('PREV_WEEKDAY_APPR_PROCESS_START_SATURDAY_MEAN', 145), ('bureau_credit_closed_count', 144), ('bureau_last_credit_update_closed_min', 142), ('CREBAL_AMT_PAYMENT_TOTAL_CURRENT_MEAN', 138), ('PREV_WEEKDAY_APPR_PROCESS_START_WEDNESDAY_MEAN', 137), ('PREV_AMT_CREDIT_MIN', 137), ('NAME_FAMILY_STATUS__Married', 132), ('CREBAL_CNT_DRAWINGS_ATM_CURRENT_VAR', 131), ('PREV_CODE_REJECT_REASON_XAP_MEAN', 128), ('PREV_CODE_REJECT_REASON_HC_MEAN', 123), ('NAME_EDUCATION_TYPE__Higher_education', 121), ('PREV_CHANNEL_TYPE_Country-wide_MEAN', 121), ('PREV_NAME_YIELD_GROUP_XNA_MEAN', 120), ('PREV_WEEKDAY_APPR_PROCESS_START_MONDAY_MEAN', 118), ('PREV_AMT_DOWN_PAYMENT_MIN', 118), ('PREV_NAME_PRODUCT_TYPE_walk-in_MEAN', 116), ('YEARS_BEGINEXPLUATATION_MODE', 115), ('CREBAL_CNT_DRAWINGS_CURRENT_MEAN', 115), ('CREBAL_AMT_PAYMENT_CURRENT_MEAN', 115), ('PREV_NAME_PRODUCT_TYPE_XNA_MEAN', 114), ('PREV_NAME_PAYMENT_TYPE_Cash_through_the_bank_MEAN', 111), ('PREV_NAME_PAYMENT_TYPE_XNA_MEAN', 108), ('PREV_NAME_YIELD_GROUP_low_action_MEAN', 107), ('PREV_NAME_TYPE_SUITE_Family_MEAN', 107), ('REGION_RATING_CLIENT_W_CITY', 105), ('PREV_WEEKDAY_APPR_PROCESS_START_SUNDAY_MEAN', 105), ('PREV_AMT_GOODS_PRICE_MAX', 103), ('PREV_RATE_DOWN_PAYMENT_MIN', 102), ('PREV_AMT_APPLICATION_MIN', 102), ('POSBAL_SK_DPD_MEAN', 101), ('PREV_NAME_SELLER_INDUSTRY_Consumer_electronics_MEAN', 100), ('POSBAL_CNT_INSTALMENT_MIN', 99), ('FLAG_WORK_PHONE', 98), ('PREV_NAME_SELLER_INDUSTRY_Connectivity_MEAN', 96), ('CREBAL_CNT_INSTALMENT_MATURE_CUM_VAR', 96), ('CREBAL_AMT_DRAWINGS_ATM_CURRENT_MEAN', 96), ('PREV_PRODUCT_COMBINATION_POS_household_with_interest_MEAN', 94), ('PREV_PRODUCT_COMBINATION_Cash_X-Sell:_high_MEAN', 93), ('PREV_NAME_CLIENT_TYPE_Repeater_MEAN', 93), ('PREV_AMT_APPLICATION_MAX', 92), ('PREV_CHANNEL_TYPE_Credit_and_cash_offices_MEAN', 91), ('FLAG_DOCUMENT_3', 91), ('PREV_NAME_PRODUCT_TYPE_x-sell_MEAN', 90), ('PREV_NAME_PORTFOLIO_POS_MEAN', 89), ('TOTALAREA_MODE', 88), ('CREBAL_AMT_PAYMENT_CURRENT_MAX', 86), ('bureau_currency_count', 85), ('PREV_NAME_PORTFOLIO_Cash_MEAN', 85), ('PREV_CHANNEL_TYPE_Contact_center_MEAN', 85), ('PREV_NAME_CLIENT_TYPE_Refreshed_MEAN', 84), ('DEF_30_CNT_SOCIAL_CIRCLE', 84), ('PREV_PRODUCT_COMBINATION_Cash_X-Sell:_low_MEAN', 83), ('PREV_PRODUCT_COMBINATION_Cash_MEAN', 79), ('PREV_CHANNEL_TYPE_Stone_MEAN', 75), ('OBS_60_CNT_SOCIAL_CIRCLE', 73), ('PREV_PRODUCT_COMBINATION_POS_mobile_with_interest_MEAN', 71), ('PREV_PRODUCT_COMBINATION_Card_X-Sell_MEAN', 71), ('PREV_NAME_CONTRACT_STATUS_Canceled_MEAN', 71), ('PREV_NAME_GOODS_CATEGORY_Mobile_MEAN', 70), ('BASEMENTAREA_MODE', 70), ('POSBAL_SK_DPD_DEF_MAX', 69), ('LANDAREA_MODE', 69), ('CREBAL_AMT_PAYMENT_TOTAL_CURRENT_MAX', 69), ('OBS_30_CNT_SOCIAL_CIRCLE', 68), ('AMT_REQ_CREDIT_BUREAU_YEAR', 68), ('PREV_NAME_GOODS_CATEGORY_Consumer_Electronics_MEAN', 67), ('CREBAL_CNT_DRAWINGS_POS_CURRENT_VAR', 67), ('CREBAL_AMT_DRAWINGS_ATM_CURRENT_MAX', 67), ('PREV_NAME_PORTFOLIO_XNA_MEAN', 66), ('PREV_PRODUCT_COMBINATION_Cash_Street:_high_MEAN', 65), ('CREBAL_AMT_BALANCE_MEAN', 64), ('YEARS_BUILD_MODE', 63), ('PREV_NAME_SELLER_INDUSTRY_XNA_MEAN', 62), ('POSBAL_SK_DPD_MAX', 62), ('POSBAL_NAME_CONTRACT_STATUS_Signed_MEAN', 62), ('LANDAREA_MEDI', 62), ('INS_PAYMENT_DIFF_MIN', 62), ('CREBAL_CNT_DRAWINGS_CURRENT_MAX', 62), ('PREV_NAME_GOODS_CATEGORY_Computers_MEAN', 61), ('NONLIVINGAREA_AVG', 61), ('LANDAREA_AVG', 61), ('ORGANIZATION_TYPE__Self-employed', 60), ('REG_CITY_NOT_LIVE_CITY', 60), ('CREBAL_AMT_DRAWINGS_CURRENT_MEAN', 60), ('PREV_PRODUCT_COMBINATION_Cash_Street:_low_MEAN', 59), ('ORGANIZATION_TYPE__Business_Entity_Type_3', 57), ('NAME_INCOME_TYPE__Working', 57), ('PREV_NAME_CASH_LOAN_PURPOSE_XNA_MEAN', 57), ('PREV_NAME_CASH_LOAN_PURPOSE_XAP_MEAN', 57), ('PREV_CHANNEL_TYPE_AP+_(Cash_loan)_MEAN', 57), ('CREBAL_AMT_CREDIT_LIMIT_ACTUAL_MEAN', 57), ('PREV_NAME_PORTFOLIO_Cards_MEAN', 56), ('CREBAL_CNT_INSTALMENT_MATURE_CUM_SUM', 56), ('AMT_REQ_CREDIT_BUREAU_QRT', 56), ('POSBAL_CNT_INSTALMENT_FUTURE_MAX', 55), ('CREBAL_AMT_DRAWINGS_CURRENT_MAX', 55), ('PREV_PRODUCT_COMBINATION_Cash_X-Sell:_middle_MEAN', 54), ('COMMONAREA_MODE', 54), ('PREV_NAME_GOODS_CATEGORY_Audio/Video_MEAN', 53), ('bureau_sum_overdue', 52), ('PREV_CODE_REJECT_REASON_SCO_MEAN', 52), ('CREBAL_AMT_CREDIT_LIMIT_ACTUAL_MIN', 51), ('YEARS_BEGINEXPLUATATION_AVG', 50), ('PREV_CHANNEL_TYPE_Regional_/_Local_MEAN', 50), ('CREBAL_CNT_INSTALMENT_MATURE_CUM_MEAN', 50), ('NAME_EDUCATION_TYPE__Secondary_/_secondary_special', 49), ('PREV_PRODUCT_COMBINATION_Card_Street_MEAN', 49), ('PREV_CODE_REJECT_REASON_LIMIT_MEAN', 49), ('PREV_PRODUCT_COMBINATION_POS_industry_with_interest_MEAN', 48), ('POSBAL_CNT_INSTALMENT_FUTURE_MIN', 48), ('YEARS_BEGINEXPLUATATION_MEDI', 47)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:75: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.034054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.097853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.037166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.043077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.163350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.034054\n",
       "1      100005  0.097853\n",
       "2      100013  0.037166\n",
       "3      100028  0.043077\n",
       "4      100038  0.163350"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "\n",
    "import gc\n",
    "import csv\n",
    "\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 2\n",
    "n_repeats = 2\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "auc_buf = []   \n",
    "\n",
    "params = {\n",
    "            'nthread':4,\n",
    "            'n_estimators':10000,\n",
    "            'learning_rate':0.02,\n",
    "            'num_leaves':34,\n",
    "            'colsample_bytree':0.9497036,\n",
    "            'subsample':0.8715623,\n",
    "            'subsample_freq':1,\n",
    "            'max_depth':8,\n",
    "            'reg_alpha':0.041545473,\n",
    "            'reg_lambda':0.0735294,\n",
    "            'min_split_gain':0.0222415,\n",
    "            'min_child_weight':39.3259775,\n",
    "            'random_state':0,\n",
    "            'verbose':-1,\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "}\n",
    "\n",
    "'''params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 12,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_threads': 8,\n",
    "        'lambda_l2': 1.5,\n",
    "        'min_gain_to_split': 0,\n",
    "    }  \n",
    "'''\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    print('Fold {}/{}'.format(cnt + 1, n_splits))\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb.Dataset(X.loc[train_index], y.loc[train_index], feature_name=X.columns.tolist()),\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb.Dataset(X.loc[valid_index], y.loc[valid_index])],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        print(tuples[:200])\n",
    "\n",
    "    p = model.predict(X.loc[valid_index], num_iteration=model.best_iteration)\n",
    "    #auc = roc_auc_score(y.loc[valid_index], p)\n",
    "\n",
    "    #print('{} AUC: {}'.format(cnt, auc))\n",
    "\n",
    "    p = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p)\n",
    "    else:\n",
    "        p_buf += np.array(p)\n",
    "    #auc_buf.append(auc)\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt > 0: # Comment this to run several folds\n",
    "        break\n",
    "    \n",
    "    del model\n",
    "    gc.collect\n",
    "\n",
    "#auc_mean = np.mean(auc_buf)\n",
    "#auc_std = np.std(auc_buf)\n",
    "#print('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))\n",
    "\n",
    "preds = p_buf/cnt\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['SK_ID_CURR'] = test['SK_ID_CURR']\n",
    "subm['TARGET'] = preds\n",
    "subm.to_csv('home-default-risk_lgbm.csv', index=False,quoting=csv.QUOTE_NONNUMERIC)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"e:/xgboost/python-package\")\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "#model = XGBClassifier()\n",
    "#model.fit(x_train, y_train)\n",
    "#print (model.score(x_train, y_train))\n",
    "\n",
    "logit_model = XGBClassifier() #LogisticRegression()  \n",
    "# Fit\n",
    "#logit_model = logit_model.fit(X_train, y_train,eval_metric='roc_auc')  \n",
    "# How accurate?\n",
    "#print (logit_model.score(X_train, y_train))  \n",
    "#0.7874\n",
    "\n",
    "# How does it perform on the test dataset?\n",
    "# Fit\n",
    "logit_model = logit_model.fit(X, y,eval_metric='auc')  \n",
    "# Predictions on the test dataset\n",
    "predicted = pd.DataFrame(logit_model.predict(X_test))  \n",
    "# Probabilities on the test dataset\n",
    "probs = pd.DataFrame(logit_model.predict_proba(X_test))  \n",
    "#prd[:,i] = np.round(probs,5)[:,1]\n",
    "#print (metrics.accuracy_score(y_test, predicted)  )\n",
    "\n",
    "print (probs.shape)\n",
    "\n",
    "prd_1 = pd.DataFrame(probs)\n",
    "\n",
    "import csv\n",
    "\n",
    "submit = pd.concat([test['SK_ID_CURR'],prd_1],axis=1)\n",
    "\n",
    "print (submit.columns.tolist)\n",
    "\n",
    "submit = submit.drop(submit.columns[1], axis=1)\n",
    "#probs.head()\n",
    "submit.to_csv('home-default-risk_xgb.csv',index=False,quoting=csv.QUOTE_NONNUMERIC)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_best_model_and_accuracy(model, params, X, y):\n",
    "    grid = GridSearchCV(model, # the model to grid search\n",
    "                        params, # the parameter set to try \n",
    "                        error_score=0., scoring='roc_auc') # if a parameter set raises an error, continue and set the performance as a big, fat 0\n",
    "    grid.fit(X, y) # fit the model and parameters\n",
    "    # our classical metric for performance\n",
    "    print (\"Best Accuracy: {}\".format(grid.best_score_))\n",
    "    # the best parameters that caused the best accuracy\n",
    "    print (\"Best Parameters: {}\".format(grid.best_params_))\n",
    "    # the average time it took a model to fit to the data (in seconds)\n",
    "    print (\"Average Time to Fit (s): {}\".format(round(grid.cv_results_['mean_fit_time'].mean(), 3)))\n",
    "    # the average time it took a model to predict out of sample data (in seconds)\n",
    "    # this metric gives us insight into how this model will perform in real-time analysis\n",
    "    print (\"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))\n",
    "\n",
    "# Logistic Regression\n",
    "lr_params = {'C':[1e-1, 1e0, 1e1, 1e2], 'penalty':['l1', 'l2']}\n",
    "\n",
    "# KNN\n",
    "knn_params = {'n_neighbors': [1, 3, 5, 7]}\n",
    "\n",
    "# Decision Tree\n",
    "tree_params = {'max_depth':[None, 1, 3, 5, 7]}\n",
    "\n",
    "# Random Forest\n",
    "forest_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 1, 3, 5, 7]}\n",
    "\n",
    "lr = LogisticRegression(penalty='l1',n_jobs=-1)\n",
    "knn = KNeighborsClassifier()\n",
    "d_tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "#get_best_model_and_accuracy(lr, lr_params, X[:3000], y[:3000])\n",
    "#get_best_model_and_accuracy(knn, knn_params, X[:3000], y[:3000])\n",
    "#get_best_model_and_accuracy(d_tree, tree_params, X[:3000], y[:3000])\n",
    "#get_best_model_and_accuracy(forest, forest_params, X[:3000], y[:3000])\n",
    "print ('Fitting...')\n",
    "\n",
    "lr.fit(X,y)\n",
    "probs = lr.predict_proba(X_test)\n",
    "print ('Predicting...')\n",
    "\n",
    "print (lr.score(X,y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prd_1 = pd.DataFrame(probs)\n",
    "\n",
    "submit = pd.concat([test['SK_ID_CURR'],prd_1],axis=1)\n",
    "\n",
    "print (submit.columns.tolist)\n",
    "\n",
    "submit = submit.drop(submit.columns[1], axis=1)\n",
    "#probs.head()\n",
    "submit.to_csv('home-default-risk.csv',index=False,quoting=csv.QUOTE_NONNUMERIC)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ax1 = sns.distplot(train[\"AMT_CREDIT\"][train.TARGET==1], color='y')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "sns.kdeplot(train.loc[train['TARGET'] == 0, 'DAYS_BIRTH'], label = 'Repaid Loan')\n",
    "sns.kdeplot(train.loc[train['TARGET'] == 1, 'DAYS_BIRTH'], label = 'Not Repaid Loan')\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Ages');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
