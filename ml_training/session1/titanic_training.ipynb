{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook\n",
    "\n",
    "A Python development environment\n",
    "\n",
    "\n",
    "Installation guide: https://jupyter.org/install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essential ML libraries:\n",
    "\n",
    "* scikit-learn\n",
    "* pandas\n",
    "* matplotlib\n",
    "* numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for ML projects usually present in the form of tabular data and manipulated via Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/schwalmdaniel/github/kaggle/titanic'\n",
    "#root = 'd:/dev/python/kaggle/titanic'\n",
    "\n",
    "train=pd.read_csv(root + \"/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explotatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see what is the shape of the data (cols, rows)\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the data types of the columns. Note that data types are inferred from the data and use 'fat' data types.\n",
    "\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally let's have a look at the data itself\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to predict whether a given person survived the disaster or not\n",
    "\n",
    "train['Survived'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**: Percentage of correct predictions made by the model\n",
    "\n",
    "\n",
    "The **Null Accuracy** for this prediction is 61%.\n",
    "\n",
    "This means that by always predicting 'not survived' we can achieve the same accuracy without creating any models.\n",
    "We have to be better than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data seriously impacts models, let us check what data is missing\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now drop Cabin due to lot of missing data\n",
    "\n",
    "train = train.drop(['Cabin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the Age feature\n",
    "train.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us fill the missing Age data with random values between the mean +- standard deviation\n",
    "\n",
    "mean = train[\"Age\"].mean()\n",
    "std = train[\"Age\"].std()\n",
    "    \n",
    "train['Age'] = train['Age'].apply(lambda x: np.random.randint(mean - std, mean + std) if np.isnan(x) else x)\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the Embarked field. Note how the describe() output looks for object or numeric types\n",
    "\n",
    "train.Embarked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns to be string\n",
    "\n",
    "train['Embarked'].fillna('',inplace=True)\n",
    "train['Embarked'] = train['Embarked'].astype(str)\n",
    "\n",
    "# fill the missing data with the most frequent value in this case\n",
    "\n",
    "train['Embarked'] = train['Embarked'].apply(lambda x: 'S' if not x or not x.strip() else x)\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We dealt with missing data now.\n",
    "\n",
    "# Machines only understand numeric data so we have to convert all columns to numeric\n",
    "\n",
    "\n",
    "# we can do it manually\n",
    "train['Sex'] = train['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "\n",
    "# or with One Hot Encoding for categorical variables\n",
    "train = pd.get_dummies(train, columns = ['Embarked','Parch'], prefix_sep='__')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passenger id does not hold any information for training, let's drop it\n",
    "# Also, drop Name and Ticket information for now, they may carry meaningful information though\n",
    "\n",
    "train = train.drop(['PassengerId','Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have only numeric data we are ready for training\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset is composed of a target variable (e.g. label) and a lot of features. \n",
    "# Usually with 'X' they refer to the features and with 'y' the target variable\n",
    "# Let us split our training set according to this\n",
    "\n",
    "X = train.drop(['Survived'], axis=1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start to train the model by splitting the training set to training and validation set\n",
    "# this way we can check how accurate is our model for previously unseen data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Training shape: %s, test shape: %s' % (X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us pick the four most frequent models in their naive form, e.g. without any fine tuning \n",
    "# run it multiple times and see what happens\n",
    "\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "d_tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "for model in [lr, knn, d_tree, forest]:\n",
    "    model.fit(X_train, y_train)\n",
    "    model.predict(X_test)\n",
    "    print ('%s accuracy score: %f' % (model.__class__.__name__, model.score(X_test, y_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,8))\n",
    "#tree.plot_tree(d_tree, fontsize=9, label='none', class_names=True, max_depth=5)\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(d_tree, out_file=dot_data, feature_names=X_train.columns,max_depth=4) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the accuracy was not bad but there was a variance in the accuracy scores\n",
    "# to get a glimpse on the average accuracy let us do a K-Fold cross validation\n",
    "# K-Fold mean\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=37)\n",
    "\n",
    "for model in [lr, knn, d_tree, forest]:\n",
    "       \n",
    "    auc_buf = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        model.predict(X_test)\n",
    "        \n",
    "        auc_buf.append(model.score(X_test, y_test))\n",
    "        \n",
    "    print ('%s mean accuracy score: %f' % (model.__class__.__name__, np.mean(auc_buf))) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pick the random forest classifier as our best model\n",
    "# and visualize our results\n",
    "# run this multiple times to see the randomness of the model\n",
    "\n",
    "model_features = list(X.columns)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#print (str(len(X.index)))\n",
    "\n",
    "for model in [forest]:\n",
    "       \n",
    "    auc_buf = []\n",
    "\n",
    "    for fold_, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        conf_mat = confusion_matrix(y_test, predictions)\n",
    "        #print(conf_mat)\n",
    "        #print(str(len(X_train.index)))\n",
    "        #print(str(len(X_test.index)))\n",
    "        \n",
    "        auc_buf.append(model.score(X_test, y_test))\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = model_features\n",
    "        fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "    print ('%s mean accuracy score: %f' % (model.__class__.__name__, np.mean(auc_buf))) \n",
    "    \n",
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x=\"importance\",y=\"feature\",data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('Most Important Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the correlation matrix\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(train.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the confusion matrix for the last prediction\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\".0f\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
