{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import re\n",
    "import sys, os, random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sys.path.insert(0, \"/Users/schwalmdaniel/github/xgboost/python-package\")\n",
    "#sys.path.insert(0, \"e:/xgboost/python-package\")\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# reproducible results\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(37)\n",
    "random.seed(17)\n",
    "\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',50)\n",
    "\n",
    "root = '/Users/schwalmdaniel/github/kaggle/ml_training/session2'\n",
    "#root = 'e:/kaggle/house_prices_kaggle'\n",
    "\n",
    "# data explanation here: https://rstudio-pubs-static.s3.amazonaws.com/155304_cc51f448116744069664b35e7762999f.html\n",
    "\n",
    "train=pd.read_csv(root + \"/kc_house_data.csv\")\n",
    "\n",
    "# have a look at the ds\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see what is the shape of the data (cols, rows)\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the data types of the columns. Note that data types are inferred from the data and use 'fat' data types.\n",
    "\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the distribution of the target variable\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.distplot(train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.price.hist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#skewness and kurtosis \n",
    "print(\"Skewness (0 means no skewness): \" + str(train['price'].skew()))\n",
    "print(\"Kurtosis (if > 3 serious outliers present): \" + str(train['price'].kurt()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train[\"price\"] = np.log1p(train[\"price\"])\n",
    "\n",
    "# print the distribution of the target variable\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.distplot(train['price'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness (0 means no skewness): \" + str(train['price'].skew()))\n",
    "print(\"Kurtosis (if > 3 serious outliers present): \" + str(train['price'].kurt()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(train.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the features in the order of correlation to the price\n",
    "\n",
    "train.corr()['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for strongly correlating the variables ( correlation > 0.99)\n",
    "\n",
    "c = train.corr().abs().unstack().sort_values(ascending=False)\n",
    "for index, value in [(i, v) for i,v in c.items() if v < 1.0][:20]:\n",
    "    print(\"{} {} {}\".format(index[0],index[1],value))\n",
    "    \n",
    "# no strongly correlating features that should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset is composed of a target variable (e.g. label) and a lot of features. \n",
    "# Usually with 'X' they refer to the features and with 'y' the target variable\n",
    "# Let us split our training set according to this\n",
    "\n",
    "X = train.drop(['id','date','price'], axis=1)\n",
    "y = train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start to train the model by splitting the training set to training and validation set\n",
    "# this way we can check how accurate is our model for previously unseen data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "print ('Training shape: %s, test shape: %s' % (X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a basic linear regression model\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the Root Mean Squared Error (RMSE) for the model. \n",
    "# This indicates how good our model is, what is the average error it is working with\n",
    "rms = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(rms)\n",
    "\n",
    "# print the R-squared (R^2) for the model. \n",
    "# This indicates how good our model is, ideally it should be between 0 and 1. \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "\n",
    "print(r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train, x_vars=['bedrooms','bathrooms','sqft_living','sqft_lot'], y_vars='price', height=7, aspect=0.7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train, x_vars=['sqft_above','sqft_basement','sqft_living15','sqft_lot15'], y_vars='price', height=7, aspect=0.7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['bedrooms'] < 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sqft_living.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['sqft_living'] < 8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sqft_lot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['sqft_lot'] < 1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sqft_lot15.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['sqft_lot15'] < 50000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sqft_living_diff'] = train['sqft_living15'] -  train['sqft_living']\n",
    "train['sqft_lot_diff'] = train['sqft_lot15'] -  train['sqft_lot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['house_age'] = 150 - (2020.0 - train['yr_built'])\n",
    "\n",
    "train['recently_renovated'] = train['yr_renovated'].apply(lambda x: 1 if x > 0 and 2020 - x < 15 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate arbitrary features from feature interactions by math operations\n",
    "\n",
    "colpairs = ['sqft_living','price','sqft_above','sqft_living15','bathrooms',\n",
    "            'sqft_basement','bedrooms','floors','sqft_lot','sqft_lot15','sqft_living_diff','sqft_lot_diff']\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "for colTuple in list(combinations(colpairs,2)):\n",
    "    col1 = colTuple[0]\n",
    "    col2 = colTuple[1]\n",
    "    \n",
    "    train[col1 + '_pow2'] = pow(train[col1],2)\n",
    "    \n",
    "    train[col1 + '_per_' + col2] = train[col1].div(train[col2])\n",
    "    train.loc[~np.isfinite(train[col1 + '_per_' + col2]), col1 + '_per_' + col2] = 0.0\n",
    "    train[col2 + '_per_' + col1] = train[col2].div(train[col1])\n",
    "    train.loc[~np.isfinite(train[col2 + '_per_' + col1]), col2 + '_per_' + col1] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset is composed of a target variable (e.g. label) and a lot of features. \n",
    "# Usually with 'X' they refer to the features and with 'y' the target variable\n",
    "# Let us split our training set according to this\n",
    "\n",
    "X = train.drop(['id','date','price'], axis=1)\n",
    "y = train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start to train the model by splitting the training set to training and validation set\n",
    "# this way we can check how accurate is our model for previously unseen data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "print ('Training shape: %s, test shape: %s' % (X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a basic linear regression model\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the Root Mean Squared Error (RMSE) for the model. This indicates how good our model is.\n",
    "# What is the average error it is working with\n",
    "rms = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(rms)\n",
    "print(r2_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
